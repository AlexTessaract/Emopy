<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>EmoPyWeb</title>
    <script
			  src="https://code.jquery.com/jquery-3.3.1.min.js"
			  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
        crossorigin="anonymous"></script>
        <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
  </head>
  <body>
    <h1>EmoPy Web Demo</h1>
    <p>
      Turn on your webcam.
      <br/> Start making smiling, surprised or disgust faces.
    </p>
    <div class="card">
      <video style="display: none;" autoplay playsinline></video>
      <canvas id="canvas"></canvas>
      <canvas id="overlay" width="640" height="480"></canvas>
      <canvas id="emotionOverlay" width="640" height="480"></canvas>
      <div class="card-footer">
        <div id="emotion"></div>
      <div id="date"> April 20, 2019 Home Office Day, NYC</div>
      <img class="logo" src="{{ url_for('static', filename='twa-logo.png') }}">
    </div>
    </div>
    <button type="button" onclick="saveImage()">Take Photo</button>
    <p>EmoPy is a deep neural net toolkit for emotion analysis via Facial Expression 
      <br/> Recognition (FER). It was initiated durring Karen Palmer residency with 
      <br/>ThoughtWorks Arts. The code is freely Available on GitHub ang released under an
      <br/>open source license (AGPL).
    </p>
    <p>EmoPy and EmoPyWeb are projects of ThoughtWorks Arts</p>
    <script type="text/javascript">
      function hasGetUserMedia() {
        return !!(navigator.mediaDevices &&
          navigator.mediaDevices.getUserMedia);
      }

      if (hasGetUserMedia()) {
        // Good to go!
      } else {
        alert('getUserMedia() is not supported by your browser');
      }

      var constraints = {
        video: true
      };

      var video = document.querySelector('video');

      function handleSuccess(stream) {
        window.stream = stream; // only to make stream available to console
        video.srcObject = stream;
        predict();
      }

      function handleError(error) {
        console.log('getUserMedia error: ', error);
      }

      navigator.mediaDevices.getUserMedia(constraints).
        then(handleSuccess).catch(handleError);

      const canvas = document.getElementById('canvas');
      const overlay = document.getElementById('overlay');
      const emotion = document.getElementById('emotionOverlay');
      overlayCtx = overlay.getContext('2d');
      emotionCtx = emotion.getContext('2d');

      function predict() {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        canvas.getContext('2d').drawImage(video, 0, 0);

        // Other browsers will fall back to image/png
        dataURL = canvas.toDataURL();
        $.ajax({
          type: "POST",
          url: "/predict",
          data:{
            image: dataURL
          }
        }).done(function(res) {
          displayEmotion(res);
        }).always(predict);
      };

      function displayEmotion(emotionPrediction){
        overlayCtx.clearRect(0, 0, overlay.width, overlay.height); // clears out previous rectangle(s)
        overlayCtx.beginPath();
        drawFaceOutlines(emotionPrediction['faces']);
        drawEmotion(emotionPrediction['emotion']);
      }

      function drawFaceOutlines(faces){
        JSON.parse(faces).forEach(function(face) {
          overlayCtx.rect(face[0], face[1], face[2], face[3]);
          overlayCtx.stroke();
        }); 
      }

      function drawEmotion(emotion){
        var img = new Image();
        img.onload = function() {
          emotionCtx.drawImage(img, 0, 0);
        }
        img.src = './static/' + emotion + '.png'

        $('#emotion').text(emotion);
      }

      function saveImage() {
        let image = canvas.toDataURL("image/png").replace("image/png", "image/octet-stream");
        window.location.href=image;
      }
      </script>
  </body>
</html>
