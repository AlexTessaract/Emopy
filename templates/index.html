<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>EmoPyWeb</title>
    <script
			  src="https://code.jquery.com/jquery-3.3.1.min.js"
			  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
        crossorigin="anonymous"></script>
        <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
  </head>
  <body>
    <h1>EmoPy Web Demo</h1>
    <p>
      Turn on your webcam.
      <br/> Start making smiling, surprised or disgust faces.
    </p>
    <div>
      <video style="display: none;" autoplay playsinline></video>
      <div id="emotion"></div>
      <canvas id="canvas"></canvas>
      <canvas id="emotionOverlay" width="640" height="480"></canvas>
      <div id="date"> April 20, 2019 Home Office Day, NYC</div>
      <img class="logo" src="{{ url_for('static', filename='twa-logo.png') }}">
    </div>
    <button type="button" onclick="saveImage()">Take Photo</button>
    <p>EmoPy is a deep neural net toolkit for emotion analysis via Facial Expression 
      <br/> (FER). It was initiated durring Karen Palmer residency with 
      <br/>ThoughtWorks Arts. The code is freely Available on GitHub ang released under an
      <br/>open source license (AGPL).
    </p>
    <p>EmoPy and EmoPyWeb are projects of ThoughtWorks Arts</p>

    <script type="text/javascript">
      function hasGetUserMedia() {
        return !!(navigator.mediaDevices &&
          navigator.mediaDevices.getUserMedia);
      }

      if (hasGetUserMedia()) {
        // Good to go!
      } else {
        alert('getUserMedia() is not supported by your browser');
      }

      var constraints = {
        video: true
      };

      var video = document.querySelector('video');

      function handleSuccess(stream) {
        window.stream = stream; // only to make stream available to console
        video.srcObject = stream;
        predict();
      }

      function handleError(error) {
        console.log('getUserMedia error: ', error);
      }

      navigator.mediaDevices.getUserMedia(constraints).
        then(handleSuccess).catch(handleError);

      const canvas = document.getElementById('canvas');
      const emotionOverlay = document.getElementById('emotionOverlay');
      emotionCtx = emotionOverlay.getContext('2d');

      function predict() {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        canvas.getContext('2d').drawImage(video, 0, 0);

        // Other browsers will fall back to image/png
        dataURL = canvas.toDataURL();
        $.ajax({
          type: "POST",
          url: "/predict",
          data:{
            image: dataURL
          }
        }).done(function(res) {
          displayEmotion(res);
        }).always(predict);
      };


      function displayEmotion(emotionPrediction){
        emotionCtx.clearRect(0, 0, emotionOverlay.width, emotionOverlay.height); // clears out previous rectangle(s)
        emotionCtx.beginPath();
        var emotion = emotionPrediction['emotion'];
        JSON.parse(emotionPrediction['faces']).forEach(function(face) {
          var img = new Image();
          var emojiSize = 50;
          img.onload = function() {
            emotionCtx.drawImage(img, face[0] - emojiSize, face[1], emojiSize, emojiSize);
            emotionCtx.drawImage(img, face[0] + face[2], face[1], emojiSize, emojiSize);
            emotionCtx.drawImage(img, face[0] + face[2]/2 - emojiSize/2, face[1] - emojiSize, emojiSize, emojiSize);
            emotionCtx.drawImage(img, face[0] + face[2] - emojiSize, face[1] - emojiSize / 1.5, emojiSize, emojiSize);
            emotionCtx.drawImage(img, face[0] - face[2]/4 + emojiSize, face[1] - emojiSize / 1.5, emojiSize, emojiSize);
          }
          img.src = './static/' + emotion + '.png'
          }); 
        $('#emotion').text(emotion);
      }


      function saveImage() {
        let image = canvas.toDataURL("image/png").replace("image/png", "image/octet-stream");
        window.location.href=image;
      }
      </script>
  </body>
</html>
